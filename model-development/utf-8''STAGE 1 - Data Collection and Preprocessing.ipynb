{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2> Import Requirements </h2>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install datapackage",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#Please ensure datapackage is installed\nimport datapackage\nimport pandas as pd\nimport numpy as np\nimport scipy as sp\nimport requests\nfrom urllib.request import urlopen",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2> Obtain Supplementary Datasets </h2>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Before proceeding to the actual preprocessing of S&P500 indicators that would possibly serve as explanatory variables, we must first download a set of supplementary datasets - list of S&P500 companies and macroeconomic indicators to be specific - that would complement micro firm-level data we obtain later in this Notebook"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#This is the S&P500 identifier data we require (symbols, names and industry sectors)\ndata_url = 'https://datahub.io/core/s-and-p-500-companies-financials/datapackage.json'\npackage = datapackage.Package(data_url)\nidentifydata = pd.read_csv(package.resources[1].descriptor['path'])\nprint(identifydata.head(n=5))",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "  Symbol                 Name                  Sector\n0    MMM           3M Company             Industrials\n1    AOS      A.O. Smith Corp             Industrials\n2    ABT  Abbott Laboratories             Health Care\n3   ABBV          AbbVie Inc.             Health Care\n4    ACN        Accenture plc  Information Technology\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "#We must now read in major macroeconomic indicators to supplement our future models\n#Out of these, stockconfurl is monthly data and thus must be separated from the yearly reporting of the remainder\nstockconfurl = 'https://www.quandl.com/api/v3/datasets/YALE/US_CONF_INDEX_VAL_INDIV.csv?api_key=UxqxiUpQzYRHVDLGsXsz'\ngdpurl = 'https://www.quandl.com/api/v3/datasets/WWDI/USA_NY_GDP_MKTP_CD.csv?api_key=UxqxiUpQzYRHVDLGsXsz'\ngniurl = 'https://www.quandl.com/api/v3/datasets/WWDI/USA_NY_GNP_MKTP_CD.csv?api_key=UxqxiUpQzYRHVDLGsXsz'\nmarketcapurl = 'https://www.quandl.com/api/v3/datasets/WWDI/USA_CM_MKT_LCAP_CD.csv?api_key=UxqxiUpQzYRHVDLGsXsz'\nconfdata = pd.read_csv(stockconfurl, error_bad_lines=False)\nconfdata.Date = confdata.Date.apply(lambda s: np.int(s.split('-')[0] + s.split('-')[1]))\neconurl = [gdpurl, gniurl, marketcapurl]\nannualecondata = pd.DataFrame()\nfor url in econurl:\n    data = pd.read_csv(url, error_bad_lines=False)\n    data.Date = data.Date.apply(lambda s: np.int(s.split('-')[0] + s.split('-')[1]))\n    if annualecondata.empty:\n        annualecondata = data.copy()\n    else:\n        annualecondata = annualecondata.merge(data, on='Date', how='outer')\n\nprint(annualecondata.head(n=10))\nprint()\nprint(confdata.head(n=5))",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "     Date       Value_x       Value_y         Value\n0  201712  1.939060e+13  1.960760e+13  3.212070e+13\n1  201612  1.862448e+13  1.896871e+13  2.735220e+13\n2  201512  1.812071e+13  1.858114e+13  2.506754e+13\n3  201412  1.742761e+13  1.789207e+13  2.633059e+13\n4  201312  1.669152e+13  1.707372e+13  2.403485e+13\n5  201212  1.615526e+13  1.659608e+13  1.866833e+13\n6  201112  1.551793e+13  1.580290e+13  1.564071e+13\n7  201012  1.496437e+13  1.512113e+13  1.728345e+13\n8  200912  1.441874e+13  1.449446e+13  1.507729e+13\n9  200812  1.471858e+13  1.479119e+13  1.159028e+13\n\n     Date  Index Value  Standard Error\n0  201904        49.50            3.52\n1  201903        47.83            3.47\n2  201902        46.63            3.74\n3  201901        47.93            3.84\n4  201812        54.48            4.30\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "identifydata.to_csv('sp500constituents.csv', index=False)\nprint(identifydata.info())\nprint()\nconfdata.to_csv('stockconfidencedata.csv', index=False)\nprint(confdata.info())\nprint()\nannualecondata.to_csv('annualecondata.csv', index=False)\nprint(annualecondata.info())\nprint()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 505 entries, 0 to 504\nData columns (total 3 columns):\nSymbol    505 non-null object\nName      505 non-null object\nSector    505 non-null object\ndtypes: object(3)\nmemory usage: 11.9+ KB\nNone\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 221 entries, 0 to 220\nData columns (total 3 columns):\nDate              221 non-null int64\nIndex Value       221 non-null float64\nStandard Error    221 non-null float64\ndtypes: float64(2), int64(1)\nmemory usage: 5.3 KB\nNone\n\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 58 entries, 0 to 57\nData columns (total 4 columns):\nDate       58 non-null int64\nValue_x    58 non-null float64\nValue_y    58 non-null float64\nValue      43 non-null float64\ndtypes: float64(3), int64(1)\nmemory usage: 2.3 KB\nNone\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2> Define Primary Data's Collection API Functions </h2>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The idea is to first separately retrieve income statement, balance sheet, key metrics and historical stock price data for each S&P500 company. The dividends paid per share in any time duration needs to actually be engineered as Dividend Yield (from key metrics data) * Share Price (from historical stock data), which is done in a later stage. In the second step, an \"allinf\" function appends all above data for each stock, and then  \"sp500inf\" code joins 500 such datasets to create our final database for S&P500 firms. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b> STEP 1: Create Company-Specific Functions for Different Sets of Financial Data </b>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Since there is a possibility that the API service returns no values for certain stocks, a try-except model is used where an empty dataframe is returned if a function is unable to retrieve appropriate data from the API. The if-else conditions for handling these empty dataframes are built into the \"allinf\" function"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def getincdata (iden):\n    incstat = 'https://financialmodelingprep.com/api/financials/income-statement/' + iden + '?datatype=csv'\n    try:\n        incdata = pd.read_csv(incstat, header=1, error_bad_lines=False)\n        incdata = incdata.T\n        incdata.columns = incdata.iloc[0,:].values\n        indexval = incdata.index.copy()\n        incdata.reset_index(drop=True, inplace=True)\n        incdata.drop([0,6], axis=0, inplace=True)\n        incdata['date'] = indexval[1:len(indexval)-1]\n        #We need to adjust columns since there are two columns named 'Basic', 'Diluted' etc., which can hurt further analysis\n        incdata = incdata.loc[:,(~incdata.columns.duplicated())]\n        incdata.rename(columns={'Basic':'Basic_EPS', 'Diluted':'Diluted_EPS'}, inplace=True)\n        return incdata\n    except:\n        print('Note: ' + iden + ' has an empty csv for income data. Skipping.')\n        return pd.DataFrame()",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def getbaldata (iden):\n    balstat = 'https://financialmodelingprep.com/api/financials/balance-sheet-statement/' + iden + '?datatype=csv'\n    try:\n        baldata = pd.read_csv(balstat, header=1, error_bad_lines=False)\n        baldata = baldata.T\n        baldata.columns = baldata.iloc[0,:].values\n        indexval = baldata.index.copy()\n        baldata.reset_index(drop=True, inplace=True)\n        baldata.drop(0, axis=0, inplace=True)\n        baldata = baldata.loc[:,(~baldata.columns.duplicated())]\n        baldata['date'] = indexval[1:]\n        return baldata\n    except:\n        print('Note: ' + iden + ' has an empty csv for balance sheet data. Skipping.')\n        return pd.DataFrame()",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def getkeymetrics (iden):\n    try:\n        metrurl = 'https://financialmodelingprep.com/api/v3/company-key-metrics/' + iden\n        metrjson = requests.get(metrurl).json()\n        metrdata = pd.io.json.json_normalize(metrjson['metrics'])\n        cols = metrdata.columns.values.tolist()\n        cols.insert(0, 'date')\n        cols = cols[0:len(cols)-1]\n        metrdata = metrdata[cols]\n        metrdata['date'] = metrdata.date.apply(lambda s: s[:len(s)-3])\n        metrdata = metrdata.loc[:,(~metrdata.columns.duplicated())]\n        return metrdata\n    except:\n        print('Note: ' + iden + ' does not have valid key metrics data. Skipping.')\n        return pd.DataFrame()",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def histstockprc (iden):\n    try:\n        stockurl = 'https://financialmodelingprep.com/api/v3/historical-price-full/' + iden + '?serietype=line'\n        stockjson = requests.get(stockurl).json()\n        stockdata = pd.io.json.json_normalize(stockjson['historical'])\n        return stockdata\n    except:\n        print('Note: ' + iden + ' does not have valid stock data. Skipping')\n        return pd.DataFrame()",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b> STEP 2: Filter Historic Stock Price Data to Yearly Values </b>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Since all other available data is on a yearly basis, we need to reduce stock price information to yearly info, and add few new features, like price change (3mths), price change (6 mths) and price change (12 mths), to accomodate micro trends. Even though this is feature engineering, it needs to be done at this stage to ensure that the actual dataset can be compiled before any other cleaning is performed"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def yearshift(base, amt):\n    mth = base % 100\n    year = (base - mth)/100\n    mth = mth + amt\n    if mth > 12:\n        year = year + (mth - (mth % 12))/12\n        mth = mth % 12\n    return int(year * 100 + mth)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def stocksimply (iden):\n    try:\n        stockdata = histstockprc(iden)\n        stockdata['time_stamp'] = stockdata.date.apply(lambda s: np.int(s.split(\"-\")[0] + s.split(\"-\")[1]))\n        mth6 = stockdata.copy()\n        mth6.time_stamp = mth6.time_stamp.apply(lambda s: yearshift(s, 6))\n        mth12 = stockdata.copy()\n        mth12.time_stamp = mth12.time_stamp.apply(lambda s: yearshift(s, 12))\n        stockdata = stockdata.merge(mth6[[\"close\", \"time_stamp\"]], on=\"time_stamp\", how=\"left\")\n        stockdata = stockdata.merge(mth12[[\"close\", \"time_stamp\"]], on=\"time_stamp\", how=\"left\")\n        stockdata = stockdata[[\"time_stamp\", \"date\", \"close_x\", \"close_y\", \"close\"]]\n        stockdata.rename(columns={\"close\":\"mth12stockratio\", \"close_y\":\"mth6stockratio\", \"close_x\":\"stockprc\"}, inplace=True)\n        stockdata.mth6stockratio = stockdata.mth6stockratio.bfill()\n        stockdata.mth12stockratio = stockdata.mth12stockratio.bfill()\n        stockdata.mth6stockratio = stockdata.stockprc / stockdata.mth6stockratio\n        stockdata.mth12stockratio = stockdata.stockprc / stockdata.mth12stockratio\n        return stockdata\n    except:\n        print('Note: ' + iden + ' does not have valid stock data. Skipping')\n        return pd.DataFrame()",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def selectstock (inc, bal, metr, stock, iden):\n    try:\n        dateval = np.nan\n        if inc.empty == False:\n            dateval = inc.date.values\n        elif bal.empty == False:\n            dateval = bal.date.values\n        elif metr.empty == False:\n            dateval = metr.date.values\n        if isinstance(dateval, np.ndarray):\n            stkkp = pd.Series(dateval).apply(lambda s: np.int(s.split(\"-\")[0] + s.split(\"-\")[1])).values\n            stock = stock[(stock.time_stamp.isin(stkkp)) & (stock.time_stamp.diff().shift(-1).fillna(1) != 0)]\n        else:\n            stock = stock[stock.time_stamp.diff().shift(-1).fillna(1) != 0]\n        stock.drop(\"time_stamp\", axis=1, inplace=True)\n        stock.date = stock.date.apply(lambda s: s[:len(s)-3])\n        return stock\n    except:\n        print('Note: ' + iden + ' does not have valid stock data. Skipping')\n        return pd.DataFrame()",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b> STEP 3: Define all Variables to be Retreived from API Calls </b>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "It is possible that the Financial Modelling Prep API that we use does not return all columns for all stocks. For example, a baldata call on 'MMM' returns 55 columns while one on 'AOS' omits 10 and gives 45 columns instead. Since all companies need to have the same variables to be appended into our initial S&P500 dataset, all non-returned variables are currently set to np.nan, and then handled later on during data cleaning"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "allvar = ['date', 'Revenue', 'Cost of revenue', 'Gross profit', 'Operating expenses', \n          'Research and development', 'Sales, General and administrative',\n          'Total operating expenses', 'Operating income', 'Interest Expense',\n          'Other income (expense)', 'Income before taxes','Provision for income taxes',\n          'Net income from continuing operations', 'Other', 'Net income',\n          'Net income available to common shareholders','Earnings per share', 'Basic_EPS', \n          'Diluted_EPS','Weighted average shares outstanding','EBITDA', 'Assets', \n          'Current assets', 'Cash','Cash and cash equivalents', 'Short-term investments',\n          'Total cash', 'Receivables', 'Inventories','Prepaid expenses',\n          'Other current assets', 'Total current assets','Non-current assets', \n          'Property, plant and equipment','Gross property, plant and equipment', \n          'Accumulated Depreciation','Net property, plant and equipment',\n          'Equity and other investments', 'Goodwill', 'Intangible assets', \n          'Prepaid pension benefit','Other long-term assets', 'Total non-current assets',\n          'Total assets', \"Liabilities and stockholders' equity\",'Liabilities', \n          'Current liabilities', 'Short-term debt','Accounts payable', 'Taxes payable',\n          'Accrued liabilities', 'Other current liabilities', 'Total current liabilities',\n          'Non-current liabilities', 'Long-term debt','Capital leases',\n          'Deferred taxes liabilities','Pensions and other benefits', 'Minority interest',\n          'Other long-term liabilities', 'Total non-current liabilities','Total liabilities', \n          \"Stockholders' equity\", 'Common stock','Additional paid-in capital', \n          'Retained earnings','Treasury stock', 'Accumulated other comprehensive income',\n          \"Total stockholders' equity\",\"Total liabilities and stockholders' equity\", \n          'Average Inventory','Average Payables', 'Average Receivables', 'Book Value per Share',\n          'Capex per Share', 'Capex to Depreciation','Capex to Operating Cash Flow', \n          'Capex to Revenue','Cash per Share', 'Current ratio', 'Days Payables Outstanding',\n          'Days Sales Outstanding', 'Days of Inventory on Hand','Debt to Assets', \n          'Debt to Equity', 'Dividend Yield','EV to Free cash flow', \n          'EV to Operating cash flow', 'EV to Sales','Earnings Yield', 'Enterprise Value',\n          'Enterprise Value over EBITDA', 'Free Cash Flow Yield','Free Cash Flow per Share', \n          'Graham Net-Net', 'Graham Number','Income Quality', 'Intangibles to Total Assets',\n          'Interest Coverage', 'Interest Debt per Share','Inventory Turnover', \n          'Invested Capital', 'Market Cap','Net Current Asset Value', 'Net Debt to EBITDA',\n          'Net Income per Share', 'Operating Cash Flow per Share','PB ratio', 'PE ratio', \n          'PFCF ratio', 'POCF ratio', 'PTB ratio','Payables Turnover', 'Payout Ratio', \n          'Price to Sales Ratio','R&D to Revenue', 'ROE', 'ROIC', 'Receivables Turnover',\n          'Return on Tangible Assets', 'Revenue per Share','SG&A to Revenue', \n          'Shareholders Equity per Share','Stock-based compensation to Revenue', \n          'Tangible Asset Value','Tangible Book Value per Share', 'Working Capital', \n          'stockprc','mth6stockratio', 'mth12stockratio']\nlen(allvar)",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "131"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<b> STEP 4: Aggregate Collected Data </b>"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def allinf (iden):\n    incdata = getincdata(iden)\n    baldata = getbaldata(iden)\n    metrdata = getkeymetrics(iden)\n    stockdata = stocksimply(iden)\n    #Error checking for all the data retreival functions\n    if (isinstance(incdata, pd.DataFrame) & isinstance(baldata, pd.DataFrame) & isinstance(metrdata, pd.DataFrame) & isinstance(stockdata, pd.DataFrame)) == False:\n        print(\"Error occured in reading data\")\n        return pd.DataFrame()\n    stockdata = selectstock(incdata, baldata, metrdata, stockdata, iden)\n    if (incdata.empty) | (baldata.empty):\n        incdata = incdata.append(baldata, ignore_index=True)\n    else:\n        incdata = incdata.merge(baldata, on=\"date\", how=\"inner\")\n    if (incdata.empty) | (metrdata.empty):\n        incdata = incdata.append(metrdata, ignore_index=True)\n    else:\n        incdata = incdata.merge(metrdata, on=\"date\", how = \"inner\")\n    if (incdata.empty) | (stockdata.empty):\n        incdata = incdata.append(stockdata, ignore_index=True)\n    else:\n        incdata = incdata.merge(stockdata, on=\"date\", how=\"inner\")\n    avcols = incdata.columns.values\n    misscols = list(set(allvar)-set(avcols))\n    for i in misscols:\n        incdata[i] = np.nan\n    incdata = incdata[allvar]\n    return incdata",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "#sp500inf: get all required S&P500 data into one single table\nmember = pd.read_csv(\"constituents_csv.csv\")\nsymbols = member['Symbol'].values\nalldata = allinf(symbols[0])\nalldata['firm'] = symbols[0]\nfor i in range(1, len(symbols)):\n    temp = allinf(symbols[i])\n    temp['firm'] = symbols[i]\n    alldata = alldata.append(temp, ignore_index=True)\n    if (i % 20 == 0):\n        print(i)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_420/lib/python3.5/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n/home/nbuser/anaconda3_420/lib/python3.5/site-packages/pandas/core/generic.py:2773: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  self[name] = value\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Note: ATVI has an empty csv for income data. Skipping.\nNote: ATVI has an empty csv for balance sheet data. Skipping.\nNote: ADBE has an empty csv for income data. Skipping.\nNote: AMD has an empty csv for income data. Skipping.\nNote: AET does not have valid key metrics data. Skipping.\nNote: ALXN has an empty csv for income data. Skipping.\nNote: ALXN has an empty csv for balance sheet data. Skipping.\n20\nNote: AGN has an empty csv for income data. Skipping.\nNote: AGN has an empty csv for balance sheet data. Skipping.\nNote: GOOG does not have valid key metrics data. Skipping.\nNote: AMZN has an empty csv for income data. Skipping.\nNote: AEE has an empty csv for balance sheet data. Skipping.\nNote: AMP has an empty csv for balance sheet data. Skipping.\nNote: AME has an empty csv for balance sheet data. Skipping.\n40\nNote: ANDV does not have valid key metrics data. Skipping.\nNote: ANTM has an empty csv for income data. Skipping.\nNote: ANTM has an empty csv for balance sheet data. Skipping.\n60\nNote: BLL has an empty csv for income data. Skipping.\nNote: BBT has an empty csv for income data. Skipping.\nNote: BDX has an empty csv for income data. Skipping.\nNote: BDX has an empty csv for balance sheet data. Skipping.\nNote: BRK.B has an empty csv for income data. Skipping.\nNote: BRK.B does not have valid key metrics data. Skipping.\nNote: BRK.B does not have valid stock data. Skipping\nNote: BRK.B does not have valid stock data. Skipping\nNote: BRK.B does not have valid stock data. Skipping\n80\nNote: BF.B has an empty csv for income data. Skipping.\nNote: BF.B does not have valid key metrics data. Skipping.\nNote: BF.B does not have valid stock data. Skipping\nNote: BF.B does not have valid stock data. Skipping\nNote: BF.B does not have valid stock data. Skipping\nNote: CA does not have valid key metrics data. Skipping.\nNote: COG has an empty csv for income data. Skipping.\nNote: COG has an empty csv for balance sheet data. Skipping.\nNote: CDNS has an empty csv for income data. Skipping.\nNote: CBG has an empty csv for income data. Skipping.\nNote: CBG does not have valid key metrics data. Skipping.\nNote: CBG does not have valid stock data. Skipping\nNote: CBG does not have valid stock data. Skipping\nNote: CBG does not have valid stock data. Skipping\n100\nNote: CHD has an empty csv for income data. Skipping.\nNote: CHD has an empty csv for balance sheet data. Skipping.\n120\nNote: GLW has an empty csv for balance sheet data. Skipping.\nNote: COTY has an empty csv for income data. Skipping.\nNote: COTY has an empty csv for balance sheet data. Skipping.\nNote: CCI has an empty csv for balance sheet data. Skipping.\nNote: CSRA does not have valid key metrics data. Skipping.\n140\nNote: DISCA has an empty csv for income data. Skipping.\nNote: DISCA has an empty csv for balance sheet data. Skipping.\nNote: DISCK does not have valid key metrics data. Skipping.\nNote: DISH has an empty csv for income data. Skipping.\nNote: DISH has an empty csv for balance sheet data. Skipping.\nNote: DOV has an empty csv for income data. Skipping.\nNote: DPS has an empty csv for balance sheet data. Skipping.\nNote: DTE has an empty csv for income data. Skipping.\nNote: DTE has an empty csv for balance sheet data. Skipping.\n160\nNote: EW has an empty csv for income data. Skipping.\nNote: EW has an empty csv for balance sheet data. Skipping.\nNote: EVHC has an empty csv for income data. Skipping.\nNote: EVHC has an empty csv for balance sheet data. Skipping.\nNote: EVHC does not have valid key metrics data. Skipping.\nNote: EXC has an empty csv for income data. Skipping.\nNote: EXC has an empty csv for balance sheet data. Skipping.\n180\nNote: ESRX does not have valid key metrics data. Skipping.\nNote: FAST has an empty csv for income data. Skipping.\nNote: FAST has an empty csv for balance sheet data. Skipping.\nNote: FLIR has an empty csv for income data. Skipping.\nNote: FLIR has an empty csv for balance sheet data. Skipping.\nNote: FL has an empty csv for income data. Skipping.\nNote: FL has an empty csv for balance sheet data. Skipping.\nNote: F has an empty csv for income data. Skipping.\nNote: F has an empty csv for balance sheet data. Skipping.\n200\nNote: BEN has an empty csv for income data. Skipping.\nNote: BEN has an empty csv for balance sheet data. Skipping.\nNote: GRMN has an empty csv for income data. Skipping.\nNote: GE has an empty csv for income data. Skipping.\nNote: GE has an empty csv for balance sheet data. Skipping.\nNote: GGP does not have valid key metrics data. Skipping.\nNote: GT has an empty csv for income data. Skipping.\nNote: GT has an empty csv for balance sheet data. Skipping.\nNote: HBI has an empty csv for income data. Skipping.\nNote: HBI has an empty csv for balance sheet data. Skipping.\n220\nNote: HIG has an empty csv for income data. Skipping.\nNote: HES has an empty csv for income data. Skipping.\nNote: HES has an empty csv for balance sheet data. Skipping.\n240\nNote: IR has an empty csv for income data. Skipping.\nNote: IR has an empty csv for balance sheet data. Skipping.\nNote: IBM has an empty csv for income data. Skipping.\nNote: IQV has an empty csv for income data. Skipping.\nNote: IQV has an empty csv for balance sheet data. Skipping.\nNote: IRM has an empty csv for income data. Skipping.\n260\nNote: JNPR has an empty csv for income data. Skipping.\nNote: KSU has an empty csv for income data. Skipping.\n280\nNote: LUK does not have valid key metrics data. Skipping.\nNote: LOW has an empty csv for income data. Skipping.\nNote: LOW has an empty csv for balance sheet data. Skipping.\nNote: LYB has an empty csv for balance sheet data. Skipping.\nNote: MMC has an empty csv for income data. Skipping.\nNote: MAS has an empty csv for income data. Skipping.\nNote: MAS has an empty csv for balance sheet data. Skipping.\nNote: MKC has an empty csv for income data. Skipping.\n300\nNote: MCD has an empty csv for income data. Skipping.\nNote: MCD has an empty csv for balance sheet data. Skipping.\nNote: KORS does not have valid key metrics data. Skipping.\nNote: TAP has an empty csv for income data. Skipping.\nNote: MON does not have valid key metrics data. Skipping.\nNote: MS has an empty csv for income data. Skipping.\nNote: MS has an empty csv for balance sheet data. Skipping.\n320\nNote: NFX has an empty csv for income data. Skipping.\nNote: NFX has an empty csv for balance sheet data. Skipping.\nNote: NFX does not have valid key metrics data. Skipping.\nNote: NEM has an empty csv for income data. Skipping.\nNote: NEM has an empty csv for balance sheet data. Skipping.\nNote: NWS has an empty csv for income data. Skipping.\nNote: NWS has an empty csv for balance sheet data. Skipping.\nNote: NWS does not have valid key metrics data. Skipping.\nNote: NOC has an empty csv for income data. Skipping.\nNote: NOC has an empty csv for balance sheet data. Skipping.\n340\nNote: PCAR has an empty csv for income data. Skipping.\nNote: PCAR has an empty csv for balance sheet data. Skipping.\n360\nNote: PX has an empty csv for income data. Skipping.\nNote: PX does not have valid key metrics data. Skipping.\nNote: PCLN has an empty csv for income data. Skipping.\nNote: PCLN does not have valid key metrics data. Skipping.\nNote: PCLN does not have valid stock data. Skipping\nNote: PCLN does not have valid stock data. Skipping\nNote: PCLN does not have valid stock data. Skipping\nNote: PGR has an empty csv for balance sheet data. Skipping.\n380\nNote: COL does not have valid key metrics data. Skipping.\n400\nNote: SCG has an empty csv for income data. Skipping.\nNote: SCG has an empty csv for balance sheet data. Skipping.\nNote: SCG does not have valid key metrics data. Skipping.\nNote: SNI has an empty csv for income data. Skipping.\nNote: SNI does not have valid key metrics data. Skipping.\nNote: SNI does not have valid stock data. Skipping\nNote: SNI does not have valid stock data. Skipping\nNote: SNI does not have valid stock data. Skipping\nNote: STX has an empty csv for income data. Skipping.\nNote: STX has an empty csv for balance sheet data. Skipping.\nNote: SWK has an empty csv for income data. Skipping.\n420\nNote: SNPS has an empty csv for income data. Skipping.\nNote: SNPS has an empty csv for balance sheet data. Skipping.\nNote: CLX has an empty csv for income data. Skipping.\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Note: CLX has an empty csv for balance sheet data. Skipping.\n440\nNote: TWX does not have valid key metrics data. Skipping.\nNote: UDR has an empty csv for balance sheet data. Skipping.\nNote: UA has an empty csv for income data. Skipping.\nNote: UA has an empty csv for balance sheet data. Skipping.\nNote: UA does not have valid key metrics data. Skipping.\n460\nNote: VTR has an empty csv for income data. Skipping.\nNote: VTR has an empty csv for balance sheet data. Skipping.\n480\nNote: HCN has an empty csv for income data. Skipping.\nNote: HCN does not have valid key metrics data. Skipping.\nNote: HCN does not have valid stock data. Skipping\nNote: HCN does not have valid stock data. Skipping\nNote: HCN does not have valid stock data. Skipping\nNote: WLTW has an empty csv for income data. Skipping.\nNote: WLTW has an empty csv for balance sheet data. Skipping.\nNote: WYN does not have valid key metrics data. Skipping.\nNote: XL does not have valid key metrics data. Skipping.\n500\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "alldata.info()",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2566 entries, 0 to 2565\nColumns: 132 entries, date to firm\ndtypes: float64(3), object(129)\nmemory usage: 2.6+ MB\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "alldata.to_csv(\"sp500alldata.csv\", index=False, header=True)",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}